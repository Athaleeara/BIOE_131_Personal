{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104857600"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "myvar100 = np.random.choice([0, 1], size=8*1024*1024*100, replace = True, p=[1.0, 0.0])\n",
    "myvar100 = np.packbits(myvar100)\n",
    "open(\"zeros_100p\", \"wb\").write(myvar100)\n",
    "\n",
    "myvar90 = np.random.choice([0, 1], size=8*1024*1024*100, replace = True, p=[0.9, 0.1])\n",
    "myvar90 = np.packbits(myvar90)\n",
    "open(\"zeros_90p\", \"wb\").write(myvar90)\n",
    "\n",
    "myvar80 = np.random.choice([0, 1], size=8*1024*1024*100, replace = True, p=[0.8, 0.2])\n",
    "myvar80 = np.packbits(myvar80)\n",
    "open(\"zeros_80p\", \"wb\").write(myvar80)\n",
    "\n",
    "myvar70 = np.random.choice([0, 1], size=8*1024*1024*100, replace = True, p=[0.7, 0.3])\n",
    "myvar70 = np.packbits(myvar70)\n",
    "open(\"zeros_70p\", \"wb\").write(myvar70)\n",
    "\n",
    "myvar60 = np.random.choice([0, 1], size=8*1024*1024*100, replace = True, p=[0.6, 0.4])\n",
    "myvar60 = np.packbits(myvar60)\n",
    "open(\"zeros_60p\", \"wb\").write(myvar60)\n",
    "\n",
    "myvar50 = np.random.choice([0, 1], size=8*1024*1024*100, replace = True, p=[0.5, 0.5])\n",
    "myvar50 = np.packbits(myvar50)\n",
    "open(\"zeros_50p\", \"wb\").write(myvar50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell I created data made of only zero and ones and wrote these to a file. I created 6 files, containing varying percentages of zeros (100, 90, 80, 70, 60,50). Each file came out to be 105MB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nucleotides = ['A', 'T', 'G', 'C']\n",
    "amino_acids = ['G', 'A', 'L', 'M', 'F', 'W', 'K', 'Q', 'E', 'S',\n",
    "                   'P', 'V', 'I', 'C', 'Y', 'H', 'R', 'N','D', 'T']\n",
    "DNA_seq = np.random.choice(nucleotides, size= 100000000, replace = True, p=[0.25, 0.25, 0.25, 0.25])\n",
    "open(\"nt_seq.fa\", \"w\").write(\"\".join(DNA_seq))\n",
    "\n",
    "prob = 1/len(amino_acids)\n",
    "probabilities = []\n",
    "for i in amino_acids:\n",
    "    probabilities.append(prob)\n",
    "\n",
    "AA_seq = np.random.choice(amino_acids, size = 100000000, replace = True, p=probabilities)\n",
    "open(\"aa_seq.fa\", \"w\").write(\"\".join(AA_seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell, I created 100MB FASTA files of random nucleotide and amino acid sequences. The probabilities of each NT/AA were equal\n",
    "\n",
    "\n",
    "All of the binary files started off as 105MB.\n",
    "All of the parts of this Markdown section follow a similar format.\n",
    "INPUT: shows what was typed into terminal\n",
    "OUTPUT: shows what terminal showed after running the command\n",
    "SIZE: I looked through the home directory and typed the size of the corresponging output file\n",
    "\n",
    "\n",
    "Description of the general input code:\n",
    "- \"time\" tells terminal to track the amount of time that the program that follows take to run\n",
    "- the argument that follows \"time\" is the compression algorithm we want to run\n",
    "- the argument \"-k\" tells terminal not to delete the original file after compression\n",
    "- the final argument is the file that the code is using as input, the file it will compress\n",
    "- ArithmeticCompress has an extra argument that tells terminal what to name the compressed files\n",
    "- GZIP names its output files \"original name\".gz\n",
    "- BZIP2 and PBZIP2 names its output files \"original name\".bz2\n",
    "- the \"-f\" argument in PBZIP2 tells terminal it is ok to overwite the file output by BZIP2 because they have the same name\n",
    "- the result of each of these compression algorithms is a compressed file stored in the home directory\n",
    "\n",
    "# Compressing \"zeros_100p\" in terminal\n",
    "\n",
    "#### GZIP:\n",
    "- INPUT: time gzip -k zeros_100p\n",
    "- OUTPUT:\n",
    "    real    0m0.698s\n",
    "    user    0m0.665s\n",
    "    sys     0m0.032s\n",
    "- SIZE of \"zeros_100p.gz\": 102kB\n",
    "\n",
    "#### BZIP2: \n",
    "- INPUT: time bzip2 -k zeros_100p\n",
    "- OUTPUT:\n",
    "     real    0m1.003s\n",
    "     user    0m0.969s\n",
    "     sys     0m0.033s \n",
    "- SIZE of \"zeros_100p.bz2\": 113B\n",
    "   \n",
    "#### PBZIP2:\n",
    "- INPUT: time pbzip2 -k zeros_100p -f\n",
    "- OUTPUT: \n",
    "    real    0m0.358s\n",
    "    user    0m1.545s\n",
    "    sys     0m0.116s\n",
    "- SIZE of \"zeros_100p.bz2\"(new one): 5.62kB\n",
    "    \n",
    "#### ArithmeticCompress\n",
    "- INPUT: time ArithmeticCompress zeros_100p zeros_100p.art\n",
    "- OUTPUT: \n",
    "     real    0m14.850s\n",
    "     user    0m14.790s\n",
    "     sys     0m0.053s\n",
    " - SIZE of \"zeros_100p.art\": 1.03kB\n",
    "    \n",
    "# Compressing \"zeros_90p\" in terminal\n",
    "#### GZIP:\n",
    "- INPUT: time gzip -k zeros_90p\n",
    "- OUTPUT:\n",
    "    real    0m18.833s\n",
    "    user    0m18.668s\n",
    "    sys     0m0.161s\n",
    "- SIZE of \"zeros_90p.gz\": 58.7MB\n",
    "\n",
    "#### BZIP2:\n",
    "- INPUT: time bzip2 -k zeros_90p\n",
    "- OUTPUT:\n",
    "    real    0m10.696s\n",
    "   user    0m10.611s\n",
    "    sys     0m0.085s\n",
    "- SIZE of \"zeros_90p.bz2\": 61.2MB\n",
    "   \n",
    "#### PBZIP2:\n",
    "- INPUT: time pbzip2 -k zeros_90p -f\n",
    "- OUTPUT: \n",
    "    real    0m0.791s\n",
    "    user    0m19.032s\n",
    "    sys     0m0.8506s\n",
    "- SIZE of \"zeros_90p.bz2\"(new one): 61.2MB  \n",
    "\n",
    "#### ArithmeticCompress:\n",
    " - INPUT: time ArithmeticCompress zeros_90p zeros_90p.art\n",
    " - OUTPUT: \n",
    "    real    0m0.785s\n",
    "    user    0m19.371s\n",
    "    sys     0m0.794s\n",
    "- SIZE of \"zeros_90p.art\": 49.2MB\n",
    "    \n",
    "# Compressing \"zeros_80p\" in terminal\n",
    "\n",
    "#### GZIP: \n",
    "- INPUT: time gzip -k zeros_80p\n",
    "- OUTPUT:\n",
    "    real    0m13.430s\n",
    "    user    0m13.279s\n",
    "    sys     0m0.124s  \n",
    "- SIZE of \"zeros_80p.gz\": 81.2MB\n",
    "\n",
    "#### BZIP2:\n",
    "- INPUT: time bzip2 -k zeros_80p\n",
    "- OUTPUT:\n",
    "    real    0m12.065s\n",
    "   user    0m11.917s\n",
    "    sys     0m0.136s\n",
    "- SIZE of \"zeros_80p.bz2\": 86.6MB\n",
    "\n",
    "#### PBZIP2:\n",
    "- INPUT: time pbzip2 -k zeros_80p -f\n",
    "- OUTPUT: \n",
    "    real    0m0.957s\n",
    "    user    0m23.464s\n",
    "   sys     0m0.829s \n",
    "- SIZE of \"zeros_80p.bz2\"(new one):  86.7 MB  \n",
    "    \n",
    "#### ArithmeticCompress    \n",
    " - INPUT: time ArithmeticCompress zeros_80p zeros_80p.art\n",
    " - OUTPUT: \n",
    "    real    0m35.450s\n",
    "    - user    0m35.146s\n",
    "    - sys     0m0.304s  \n",
    "- SIZE of \"zeros_80p.art\": 75.7MB\n",
    " \n",
    "# Compressing \"zeros_70p\" in terminal\n",
    "\n",
    "#### GZIP:\n",
    "- INPUT: time gzip -k zeros_70p\n",
    "- OUTPUT:\n",
    "   real    0m6.186s\n",
    "    user    0m5.894s\n",
    "   sys     0m0.168s\n",
    "- SIZE of \"zeros_70p.gz\": 93.6MB\n",
    "\n",
    "#### BZIP2:\n",
    "- INPUT: time bzip2 -k zeros_70p\n",
    "- OUTPUT:\n",
    " real    0m13.852s\n",
    "   user    0m13.728s\n",
    "    sys     0m0.124s \n",
    "- SIZE of \"zeros_70p.bz2\": 99.8MB\n",
    "\n",
    "#### PBZIP2:\n",
    "- INPUT: time pbzip2 -k zeros_70p -f\n",
    "- OUTPUT: \n",
    "    real    0m1.176s\n",
    "     user    0m29.812s\n",
    "    sys     0m0.933s   \n",
    "- SIZE of \"zeros_80p.bz2\"(new one): 99.8MB\n",
    "\n",
    "#### ArithmeticCompress\n",
    " - INPUT: time ArithmeticCompress zeros_70p zeros_70p.art\n",
    " - OUTPUT: \n",
    "     real    0m39.354s\n",
    "   user    0m38.982s\n",
    "    sys     0m0.312s \n",
    "- SIZE of \"zeros_70p.art\": 92.4MB\n",
    "    \n",
    "# Compressing \"zeros_60p\" in terminal\n",
    " \n",
    " #### GZIP:\n",
    " - INPUT: time gzip -k zeros_60p\n",
    " - OUTPUT:\n",
    "    real    0m4.292s\n",
    "    user    0m4.227s\n",
    "    sys     0m0.040s \n",
    "- SIZE of \"zeros_60p.gz\": 102MB\n",
    "\n",
    "#### BZIP2:\n",
    "- INPUT: time bzip2 -k zeros_60p\n",
    "- OUTPUT:\n",
    "    real    0m15.685s\n",
    "    user    0m15.545s\n",
    "    sys     0m0.140s \n",
    "- SIZE of \"zeros_60p.bz2\": 105MB\n",
    "\n",
    "#### PBZIP2:\n",
    "- INPUT: time pbzip2 -k zeros_60p -f\n",
    "- OUTPUT: \n",
    "    real    0m1.404s\n",
    "    user    0m36.560s\n",
    "    sys     0m0.850s   \n",
    "- SIZE of \"zeros_60p.bz2\"(new one): 105MB\n",
    "\n",
    "#### ArithmeticCompress:\n",
    " - INPUT: time ArithmeticCompress zeros_60p zeros_60p.art\n",
    " - OUTPUT: \n",
    "     real    0m1.404s\n",
    "     user    0m36.560s\n",
    "    sys     0m0.850s\n",
    "- SIZE of \"zeros_60p.art\": 102MB\n",
    "    \n",
    "# Compressing \"zeros_50p\" in terminal\n",
    " \n",
    " #### GZIP: \n",
    "- INPUT: time gzip -k zeros_50p\n",
    "- OUTPUT:\n",
    "     real    0m3.759s\n",
    "     user    0m3.485s\n",
    "    sys     0m0.145s    \n",
    "- SIZE of \"zeros_50p.gz\": 105MB \n",
    "\n",
    "#### BZIP2:\n",
    "- INPUT: time bzip2 -k zeros_50p\n",
    "- OUTPUT:\n",
    "    real    0m16.631s\n",
    "    user    0m16.482s\n",
    "    sys     0m0.149s\n",
    "- SIZE of \"zeros_50p.bz2\": 105MB \n",
    "   \n",
    "#### PBZIP2:    \n",
    "- INPUT: time pbzip2 -k zeros_50p -f\n",
    "- OUTPUT: \n",
    "   real    0m1.460s\n",
    "    user    0m39.467s\n",
    "    sys     0m0.922s  \n",
    "- SIZE of \"zeros_50p.bz2\"(new one): 105MB\n",
    "\n",
    "#### ArithmeticCompress\n",
    " - INPUT: time ArithmeticCompress zeros_50p zeros_50p.art\n",
    " - OUTPUT: \n",
    "     real    0m40.950s\n",
    "    user    0m40.684s\n",
    "    sys     0m0.241s\n",
    "- SIZE of \"zeros_50p.art\": 105MB\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressing AA file \"aa_seq.fa\"\n",
    "\n",
    "The size of this file initially was 100MB\n",
    "\n",
    " #### GZIP: \n",
    "- INPUT: time gzip -k aa_seq.fa\n",
    "- OUTPUT:\n",
    " real    0m4.244s\n",
    "    user    0m4.175s\n",
    "    sys     0m0.065s \n",
    "      \n",
    "- SIZE of \"aa_seq.fa.gz\": 60.6 MB\n",
    "\n",
    "#### BZIP2:\n",
    "- INPUT: time bzip2 -k aa_seq.fa\n",
    "- OUTPUT:\n",
    "     real    0m9.975s\n",
    "    user    0m9.910s\n",
    "    sys     0m0.065s  \n",
    "- SIZE of \"aa_seq.fa.bz2\": 55.3MB \n",
    "   \n",
    "#### PBZIP2:    \n",
    "- INPUT: time pbzip2 -k aa_seq.fa -f\n",
    "- OUTPUT: \n",
    "    real    0m0.799s\n",
    "    user    0m19.049s\n",
    "    sys     0m0.779s   \n",
    "- SIZE of \"aa_seq.fa.bz2\"(new one): 55.3MB\n",
    "\n",
    "#### ArithmeticCompress\n",
    " - INPUT: time ArithmeticCompress aa_seq.fa aa_seq.fa.art\n",
    " - OUTPUT: \n",
    "    real    0m28.621s\n",
    "    user    0m28.343s\n",
    "    sys     0m0.277s   \n",
    "- SIZE of \"aa_seq.fa.art\": 54MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressing NT file \"nt_seq.fa\"\n",
    "\n",
    "The size of this file initially was 100MB\n",
    "\n",
    " #### GZIP: \n",
    "- INPUT: time gzip -k nt_seq.fa\n",
    "- OUTPUT:\n",
    "    real    0m12.163s\n",
    "    user    0m12.077s\n",
    "    sys     0m0.081s   \n",
    "- SIZE of \"nt_seq.fa.gz\": 29.2MB \n",
    "\n",
    "#### BZIP2:\n",
    "- INPUT: time bzip2 -k nt_seq.fa\n",
    "- OUTPUT:\n",
    "     real    0m9.481s\n",
    "    user    0m9.400s\n",
    "    sys     0m0.081s\n",
    "- SIZE of \"nt_seq.fa.bz2\": 27.3MB\n",
    "   \n",
    "#### PBZIP2:    \n",
    "- INPUT: time pbzip2 -k nt_seq.fa -f\n",
    "- OUTPUT: \n",
    "     real    0m0.685s\n",
    "    user    0m16.271s\n",
    "   sys     0m0.757s  \n",
    "- SIZE of \"nt_seq.fa.bz2\"(new one): 27.3MB  \n",
    "\n",
    "#### ArithmeticCompress\n",
    " - INPUT: time ArithmeticCompress nt_seq.fa nt_seq.fa.art\n",
    " - OUTPUT: \n",
    "    real    0m28.621s\n",
    "    user    0m28.343s\n",
    "    sys     0m0.277s  \n",
    "- SIZE of \"nt_seq.fa.art\": 25MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In my opinion it is difficult to compare and interpret the results in this way so I made lists below. I would plot if there was more time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"GZIP\", \"BZIP2\", \"PBZIP2\", \"ArtComp\"]\n",
    "r100p = ['.012', '1.13e-5', '.00562', '.00103']\n",
    "r90p = ['58.7', '61.2', '61.2', '49.2']\n",
    "r80p = ['81.2', '86.6', '86.7', '75.5']\n",
    "r70p = ['93.6', '98.8', '98.8', '92.4']\n",
    "r60p = ['102', '105', '105', '102']\n",
    "r50p = ['105', '105', '105', '105']\n",
    "aa_rand = ['60.6', '55.3', '55.3', '54']\n",
    "nt_rand = ['29.2', '27.3', '27.3', '25']\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUESTIONS: \n",
    "\n",
    "#### - Which algorithm achieves the best level of compression on each file type?\n",
    "\n",
    "There is no algorithm that achieves the best level of compression for EVERY file type. BZIP2 seems to be the best for random nucleotide sequences and ArithmeticCompress the best for random amino acid sequences. For the binary file with all zeros, BZIP also achieved the most compression. For 90% zero, it was GZIP. For 80% and 70% zero, it was ArithmeticCompress. For 60% zeros, it was ArithmeticCompress and GZIP. There was no compression at 50% zeros becasue it is not possible. A general observation is that ArithmeticCompress takes a long time but does a good job compressing sequences close to random. \n",
    "\n",
    "#### - Which algorithm is the fastest?\n",
    "\n",
    "It depends on the situation but in general it appeared that GZIP ran fast consistently and ArithmeticCompress ran slow consitently\n",
    "\n",
    "\n",
    "#### - What is the difference between bzip2 and pbzip2? Do you expect one to be faster and why?\n",
    "\n",
    "I googled the difference between the two and it says \"pbzip2 is a parallel implementation of the bzip2 block-sorting file compressor that uses pthreads and achieves near-linear speedup on SMP machines.\" (https://www.systutorials.com/docs/linux/man/1-pbzip2/) . The way that I understand this is that in general we should expect pbzip to be faster, but in some cases, as we see when looking at the time records above, this is not true. \n",
    "\n",
    "\n",
    "#### - How does the level of compression change as the percentage of zeros increases? Why does this happen?\n",
    "\n",
    "As the percentage of zeros increases the level of compression increases. This happens because, like we discussed in class, a sequence with non-unifor composition can be compressed to fewer than 1 bit per zero or one by constructing a code to compensate for the most common symbol/sequence of symbold. For example, in the 100% zero file, the compression algorithm only needs to count the number of zeros and store that, significantly reducing the size of the file. We cannot do this for the 50% zero file because it has uniform composition. That is why we see no compression. \n",
    "\n",
    "\n",
    "#### - What is the minimum number of bits required to store a single DNA base?\n",
    "min number of bits = log2(4) = 2 bits are required\n",
    "    \n",
    "    \n",
    "#### - What is the minimum number of bits required to store an amino acid letter?\n",
    "min number of bits = log2(20) = 4.3\n",
    "so 5 bit minimum are required\n",
    "\n",
    "\n",
    "#### - In your tests, how many bits did gzip and bzip2 actually require to store your random DNA and protein sequences?\n",
    "The size of the GZIP compressed file for the random protein and DNA sequences respectively were 60.2MB and 29.2MB.\n",
    "This is 60.2*1000000*8bits = 481,600,000 bits and 29.2*1000000*8bits = 233,600,000 bits. \n",
    "For BZIP2 the compressed file sizes were 55.3MB and 27.3MB (AA then NT).\n",
    "This is 55.3*1000000*8bits = 442,400,000 bits and 27.3*1000000*8 bits = 218,400,000 bits. \n",
    "\n",
    "#### - Are gzip and bzip2 performing well on DNA and proteins?\n",
    "We calculated the actual value of bits above. Below are the expected (minimum values). \n",
    "There are 100,000,000 bases/amino acids in each file. \n",
    "We would guess that the number of bits this would take to represent 100 million bases would be 100,000,000*2bits per nucleotiede = 200,000,000.* The GZIP and BZIP take 233,600,000 bits and 218,400,000 bits so they were both relatively close to the ideal value! Relative percentages are 116.8% and 109.2% greater than the ideal. \n",
    "\n",
    "The GZIP and BZIP take 481,600,000 bits and 442,400,000 bits respectively. There minimum number of bits is 100,000,000 x 4bits per amino acid = 400,000,000 bits so they are also relatively close to the ideal value for amino acids! . Relative percentages are 120.4% and 110.6% respectively greater than ideal. \n",
    "\n",
    "It seems also that BZIP is more useful than GZIP in BOTH cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1482418361', '1482418359', '1482418357', '1482418355', '1482418353', '1482418351', '1482418349', '1482418347', '1482418345', '1482418343']\n"
     ]
    }
   ],
   "source": [
    "from Bio import Entrez\n",
    "Entrez.email = \"ngoodwin97@berkeley.edu\"\n",
    "handle = Entrez.esearch(db= \"nucleotide\", retmax = 10, term = 'gp120')\n",
    "record = Entrez.read(handle)\n",
    "handle.close()\n",
    "\n",
    "gp120_ids = [x for x in record[\"IdList\"]]\n",
    "print(gp120_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above cell searches the NCBI nucleotide database for 'gp120' and stores the IDs of the first 10 results as a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "file = open(\"seqs.gb\", \"w\")\n",
    "list_seq, list_name = [], []\n",
    "for i in gp120_ids:\n",
    "    handle = Entrez.efetch(db=\"nucleotide\", id= i, rettype= \"gb\", retmode=\"fasta\")\n",
    "    record = SeqIO.read(handle, \"genbank\")\n",
    "    handle.close()\n",
    "    list_seq.append(str(record.seq))\n",
    "    list_name.append(record.name)\n",
    "    \n",
    "file = open(\"gp120_seqs.fa\", \"w\")\n",
    "for i in range(len(list_seq)):\n",
    "    file.write(\">\" + list_name[i] + \"\\n\" +list_seq[i] + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the ID list created above to fetch the nucleotide sequences from the database. I created two lists, one with each nucleotide sequence as a string and the other with each name as a string. I then wrote a FASTA file using the standard FASTA composition format. \n",
    "\n",
    "\n",
    "No info was pulled from a web browser, here is a summary of the contents of the multi FASTA file:\n",
    "\n",
    "\">MH727386\n",
    "\n",
    "\n",
    "GCAGAAG...........GTACTTAC\"\n",
    "\n",
    "\n",
    "The dots represent omitted nucleotides. There are 10 of the segement is in the quotation marks in the FASTA file. \n",
    "\n",
    "# QUESTION \n",
    "\n",
    "#### A priori, do you expect to achieve better or worse compression here than random data? Why?\n",
    "\n",
    "Expect better compression here than with random data because the compression algorithms can take advantage of the similarity between the 10 homologs in order to create code that encodes more information in fewer bits. Since there are not patterns in random data, we cannot generate codes to encode common motifs in a useful way like we can for pattern-like, repetitive data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressing FASTA file \"gp120_seqs.fa\"\n",
    "\n",
    "The size of this file initially was 3.94kB\n",
    "\n",
    " #### GZIP: \n",
    "- INPUT: time gzip -k gp120_seqs.fa\n",
    "- OUTPUT:\n",
    "    real    0m0.010s\n",
    "    user    0m0.002s\n",
    "    sys     0m0.001s   \n",
    "- SIZE of \"nt_seq.fa.gz\": 803B\n",
    "\n",
    "#### BZIP2:\n",
    "- INPUT: time bzip2 -k gp120_seqs.fa\n",
    "- OUTPUT:\n",
    "    real    0m0.002s\n",
    "    user    0m0.002s\n",
    "    sys     0m0.000s \n",
    "- SIZE of \"gp120_seqs.fa.bz2\": 809B\n",
    "   \n",
    "#### ArithmeticCompress\n",
    " - INPUT: time ArithmeticCompress gp120_seqs.fa gp120_seqs.fa.art\n",
    " - OUTPUT: \n",
    "    real    0m0.004s\n",
    "    user    0m0.004s\n",
    "    sys     0m0.000s\n",
    "    \n",
    "- SIZE of \"nt_seq.fa.art\": 2.05kB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question \n",
    "\n",
    "### How does the compression ratio of this file compare to random data?\n",
    " \n",
    "#### Compression Ratio for Random Data (only relevant one to consider is the random NT sequence \"nt_seq.fa\")\n",
    "    - Original size: 100MB\n",
    "    -Size after GZIP: 29.2MB therefore compression ratio is 0.292\n",
    "    -Size after BZIP: 27.3MB therefore compression ratio is 0.273\n",
    "    -Size after ArithmeticCompress: 25MB therefore the compression ratio is 0.25\n",
    "    \n",
    "#### Compression Ratio for multi FASTA file\n",
    "    - Original Size: 3.94kB\n",
    "    -Size after GZIP: 803B therefore compression ratio is 0.204\n",
    "    -Size after BZIP: 809B therefore compression ratio is 0.205\n",
    "    -Size after ArithmeticCompress: 2.05kB therefore the compression ratio is 0.52\n",
    "    \n",
    "Based on the calculated compression ratios, it is clear that BZIP and GZIP were able to compress the multi FASTA file by a larger factor than they were able to compress the random data. The opposite was the case for ArithmeticCompress. ArithmeticCompress compressed the random data almost a factor of two more than the multi FASTA data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL QUESTION \n",
    "\n",
    "#### Q: \"Let’s make some assumptions about the contents of the data at your biotech company. Most of the data, say 80%, is re-sequencing of genomes and plasmids that are very similar to each other. Another 10% might be protein sequences, and the last 10% are binary microscope images which we’ll assume follow the worst-case scenario of being completely random. Given the benchmarking data you obtained in this lab, which algorithm do you propose to use for each type of data? Provide an estimate for the fraction of space you can save using your compression scheme. How much of a bonus do you anticipate receiving this year?\"\n",
    "\n",
    "A: \n",
    "For the genomes and plasmids that are similar to each other, I would use the GZIP algorithm based on the benchmarking data and condidering that for similar nucleotide sequences, it was able to compress by a factor of 0.204. This was the most compression out of all the algorithms attempted. GZIP in an above analysis was also identified to be the fastest. Since this portion makes up 80% of the data, it seems reasonable to use the fastest compression algorithm. \n",
    "\n",
    "For the protein sequences, I would use BZIP2 or PBZIP2 (since it is supposed to be faster for larger scale things, even though I did not see this in my benchmark data). BZIP2 was earlier identified as the best to handle random protien sequences. See answer to question: Are gzip and bzip2 performing well on DNA and proteins?. In short, they wore both performing well, but BZIP2 was performing better, on such a large scale these differences would be siginificant. \n",
    "\n",
    "For the binary microscope images I would use ArithmeticCompress because it was the best at compressing data that was close to random, like the 80, 70, and 60 percent zero files. This algorithm takes the longest but thankfully, it would only be running on 10% of the data. \n",
    "\n",
    "To predict the amount of space that I would save: \n",
    "\n",
    "Compression factor for GZIP on similar sequences: 0.204 \n",
    "Compression factor for BZIP2 on protein: 55.3MB/100MB = .553\n",
    "Compression factor for ArithmeticCompress on close to random binary: 92.4MB/105MB (compression at 70% zeros) = 0.88\n",
    "\n",
    "80% of 1000 Terabytes = 800 Terabytes\n",
    "10% of 1000 Terabytes = 100 Terabytes\n",
    "\n",
    "Considering Compression:\n",
    "\n",
    "0.204 x 800 Terabytes = 163.2 Terabytes\n",
    "0.552 x 100 Terabytes = 55.2 Terabytes\n",
    "0.88 x 100 Terabytes = 88 Terabytes\n",
    "\n",
    "Total Storage After Compression = 163.2 + 55.2 + 88 Terabytes = 306.4 Terabytes\n",
    "\n",
    "Difference between start and end = 1000 Terabytes - 306.4 Terabytes = 693.6 Terabytes SAVED!!\n",
    "\n",
    "500$ per 1% reduction \n",
    "\n",
    "69.36% reduction so 69.36 x $500 = $34,680 BONUS!!\n",
    "\n",
    "I did not consider time to run this in my estimatation becasue if all three algorithms were run simultanously. They would all finish compressing MOST of their respective number of terabytes of data within 24hours. \n",
    "\n",
    "Ex: To compress 100MB of relevant data, it took GZIP 0.010s. If this time scales linearly, it will take 100,000 seconds, which is 27.7 hours. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
